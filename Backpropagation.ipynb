{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BACKPROPAGATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JFamxZEfUhPd"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "#import math\n",
    "from numpy import genfromtxt\n",
    "#from random import seed\n",
    "from random import random as rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "colab_type": "code",
    "id": "ZqxgcCdEUhPh",
    "outputId": "cd9c6b5e-3d99-4a15-d3dc-c4e8201d7e6c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "data_frame = pd.read_csv(\"train_data.csv\", header=None)\n",
    "labels_frame = pd.read_csv(\"train_labels.csv\", header=None)\n",
    "\n",
    "labels=np.array(labels_frame)\n",
    "data=np.array(data_frame)\n",
    "\n",
    "count = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24754, 788)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.append(data, labels, axis=1)#Attaching labels at the end of train data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling rows before splitting\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining data splitting function\n",
    "def dataSplit(data, split_at):\n",
    "    np.random.shuffle(data)\n",
    "    return data[:split_at,:] , data[split_at:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 2475\n",
      "train: 22279\n",
      "train final: 17823\n",
      "validation: 4456\n"
     ]
    }
   ],
   "source": [
    "#Splitting data into train and test sets\n",
    "train_count = round(count*0.9)\n",
    "#print(test_count + train_count)\n",
    "train_data , test_data = dataSplit(data, train_count)\n",
    "print(\"test:\", len(test_data))\n",
    "print(\"train:\", len(train_data))\n",
    "\n",
    "# validating the train data further\n",
    "valid_count = round(train_count*0.2)\n",
    "valid_data, train_data = dataSplit(train_data, valid_count)\n",
    "print(\"train final:\", len(train_data))\n",
    "print(\"validation:\", len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:,-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_data[:, :784]\n",
    "y_train=train_data[:,-4:]\n",
    "X_test = test_data[:, :784]\n",
    "y_test=test_data[:,-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 784\n",
    "hidden_nodes =  260\n",
    "n_outputs = 4 \n",
    "\n",
    "wh = np.random.rand(n_inputs,hidden_nodes)\n",
    "bh = np.random.randn(hidden_nodes)\n",
    "\n",
    "wo = np.random.rand(hidden_nodes,n_outputs)\n",
    "bo = np.random.randn(n_outputs)\n",
    "lr = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function named sigmoid() that implements the sigmoid equation.\n",
    "def sigmoid(x):\n",
    "    return np.where(x >= 0, \n",
    "                    1 / (1 + np.exp(-x)), \n",
    "                    np.exp(x) / (1 + np.exp(x)))\n",
    "#1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_der(x):\n",
    "    return sigmoid(x) *(1-sigmoid (x))\n",
    "# function named softmax() that implements the sigmoid equation.\n",
    "def softmax(x):\n",
    "    #expA = np.exp(A)\n",
    "    #return expA / expA.sum(axis=1, keepdims=True)\n",
    "    z = x - np.max(x, axis=-1, keepdims=True)\n",
    "    numerator = np.exp(z)\n",
    "    denominator = np.sum(numerator, axis=-1, keepdims=True)\n",
    "    softmax = numerator / denominator\n",
    "    return softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function value:  357020.42383890785\n",
      "Loss function value:  357020.42383890785\n",
      "Loss function value:  286178.6345199053\n",
      "Loss function value:  371416.18584030715\n",
      "Loss function value:  374952.95654314617\n",
      "Loss function value:  357020.42383890785\n",
      "Loss function value:  374013.5018252045\n",
      "Loss function value:  371416.18584030715\n",
      "Loss function value:  374952.95654314617\n",
      "Loss function value:  374952.95654314617\n",
      "Loss function value:  371416.18584030715\n",
      "Loss function value:  374013.5018252045\n",
      "Loss function value:  374013.5018252045\n",
      "Loss function value:  357020.42383890785\n"
     ]
    }
   ],
   "source": [
    "error_cost = []\n",
    "\n",
    "for epoch in range(700):\n",
    "# Forward propagate input to a network output\n",
    "\n",
    "    # Phase 1\n",
    "    #Calculating input to hidden layer\n",
    "    zh = np.dot(X_train, wh) + bh\n",
    "    #Output of hidden layer\n",
    "    ah = np.tanh(zh)\n",
    "\n",
    "    # Phase 2\n",
    "    #Input to output layer\n",
    "    zo = np.dot(ah, wo) + bo\n",
    "    #Output of output layer\n",
    "    ao = softmax(zo)\n",
    "    \n",
    "# Back Propogation  \n",
    "    #Differentiating cost wrt weights so that weights can be updated\n",
    "    #Differentiating cost wrt to output layer weights in order to update them in the end.\n",
    "    dcost_dzo = ao - y_train\n",
    "    dzo_dwo = ah\n",
    "\n",
    "    dcost_wo = np.dot(dzo_dwo.T, dcost_dzo)\n",
    "\n",
    "    dcost_bo = dcost_dzo\n",
    "    \n",
    "    dzo_dah = wo\n",
    "    dcost_dah = np.dot(dcost_dzo , dzo_dah.T)\n",
    "    dah_dzh = 1-np.power(ah,2)\n",
    "    dzh_dwh = X_train\n",
    "    dcost_wh = np.dot(dzh_dwh.T, dah_dzh * dcost_dah)\n",
    "    \n",
    "    dcost_bh = dcost_dah * dah_dzh\n",
    "\n",
    "    # # Update network weights\n",
    "    \n",
    "    wh -= lr * dcost_wh\n",
    "    bh -= lr * dcost_bh.sum(axis=0)\n",
    "\n",
    "    wo -= lr * dcost_wo\n",
    "    bo -= lr * dcost_bo.sum(axis=0)\n",
    "    \n",
    "    #Printing loss function value after every 50 epochs\n",
    "    if epoch % 50 == 0:\n",
    "        loss = np.sum(-np.log(np.sum(y_train * ao, axis=1)+ 1e-12) )\n",
    "        print('Loss function value: ', loss)\n",
    "        error_cost.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "zh = np.dot(X_test, wh) + bh\n",
    "ah = np.tanh(zh)\n",
    "\n",
    "# Phase 2\n",
    "# Make a prediction with a network\n",
    "zo = np.dot(ah, wo) + bo\n",
    "ao = softmax(zo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Creating an array of max values per row.\n",
    "rowmax = np.amax(ao, 1).reshape(len(ao), 1)\n",
    "\n",
    "#Matching the shape of rowmax with softmax outputs\n",
    "rowmax = rowmax.reshape(len(rowmax),1)\n",
    "rowmax = np.append(rowmax, rowmax, axis=1)\n",
    "rowmax = np.append(rowmax, rowmax, axis=1)\n",
    "\n",
    "#Saving as one hot labels\n",
    "predictions = (ao == rowmax).astype(np.uint8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    if not (len(y_true) == len(y_pred)):\n",
    "        print('Size of predicted and true labels not equal.')\n",
    "        return 0.0\n",
    "\n",
    "    corr = 0\n",
    "    for i in range(0,len(y_true)):\n",
    "        corr += 1 if (y_true[i] == y_pred[i]).all() else 0\n",
    "\n",
    "    return corr/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy = accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.61712439418416"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savetxt, loadtxt\n",
    "\n",
    "savetxt('w1.csv', wh,delimiter=',')\n",
    "savetxt('b1.csv', bh,delimiter=',')\n",
    "savetxt('w2.csv', wo,delimiter=',')\n",
    "savetxt('b2.csv', bo,delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "1. https://stackabuse.com/creating-a-neural-network-from-scratch-in-python-multi-class-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "    network = list()\n",
    "    hidden_layer = [{'weights':[rn() for i in range(n_inputs)]} for i in range(n_hidden)]\n",
    "    network.append(hidden_layer)\n",
    "    output_layer = [{'weights':[rn() for i in range(n_hidden)]} for i in range(n_outputs)]\n",
    "    network.append(output_layer)\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = initialize_network(4, 2, 3)\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KlnFeeyeUhPo"
   },
   "outputs": [],
   "source": [
    "# Initialize a network\n",
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "    \n",
    "    hidden_layer = [{'weights':[rn() for i in range(n_inputs)]} for i in range(n_hidden)]\n",
    "    network.append(hidden_layer)\n",
    "    output_layer = [{'weights':[rn() for i in range(n_hidden)]} for i in range(n_outputs)]\n",
    "    network.append(output_layer)\n",
    "    return network\n",
    " \n",
    "seed(1)\n",
    "#network = initialize_network(4, 2, 3)\n",
    "#for layer in network:\n",
    "#    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sAL0ivubUhPs"
   },
   "outputs": [],
   "source": [
    "# Calculate neuron activation for an input\n",
    "def activate(weights, inputs):\n",
    "    activation = 0\n",
    "    for i in range(len(weights)-1):\n",
    "        activation += weights[i] * inputs[i]\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xR9hsM9WUhPv"
   },
   "outputs": [],
   "source": [
    "# Transfer neuron activation\n",
    "def transfer(z):\n",
    "    return np.exp(z) / np.sum(np.exp(z),axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MGaEwZbuUhPz"
   },
   "outputs": [],
   "source": [
    "# Forward propagate input to a network output\n",
    "def forward_propagate(network, row):\n",
    "    inputs = row\n",
    "    for layer in network:\n",
    "        new_inputs = []\n",
    "        for neuron in layer:\n",
    "            activation = activate(neuron['weights'], inputs)\n",
    "            neuron['output'] = transfer(activation) # activation ko o/p mai transfer kiya\n",
    "            new_inputs.append(neuron['output'])\n",
    "        inputs = new_inputs\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bxJX6_YxUhP2"
   },
   "outputs": [],
   "source": [
    "# Calculate the derivative of an neuron output\n",
    "def transfer_derivative(output):\n",
    "    return output * (1.0 - output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VevYcP36UhP5"
   },
   "outputs": [],
   "source": [
    "# Backpropagate error and store in neurons\n",
    "def backward_propagate_error(network, expected):\n",
    "    for i in reversed(range(len(network))):\n",
    "        layer = network[i]\n",
    "        errors = list()\n",
    "        if i != len(network)-1:\n",
    "            for j in range(len(layer)):\n",
    "                error = 0.0\n",
    "                for neuron in network[i + 1]: #o/p layer ki neurons ki baat ho ri hai[0,1]\n",
    "                    error += (neuron['weights'][j] * neuron['delta']) #j is frst neuron\n",
    "                errors.append(error)\n",
    "        else:\n",
    "            for j in range(len(layer)):\n",
    "                neuron = layer[j]\n",
    "                errors.append(expected[j] - neuron['output'])\n",
    "        for j in range(len(layer)):\n",
    "            neuron = layer[j]\n",
    "            neuron['delta'] = errors[j] * transfer_derivative(neuron['output']) #o/p layer ke neurons ka delta\n",
    "            \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1RYDsRMtUhP8"
   },
   "outputs": [],
   "source": [
    "# Update network weights with error\n",
    "def update_weights(network, row, l_rate):\n",
    "    for i in range(len(network)):\n",
    "        inputs = row[:-1]\n",
    "        if i != 0:\n",
    "            inputs = [neuron['output'] for neuron in network[i - 1]]\n",
    "        for neuron in network[i]:\n",
    "            for j in range(len(inputs)):\n",
    "                neuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n",
    "            neuron['weights'][-1] += l_rate * neuron['delta'] # for bias\n",
    "\n",
    "#forward_propagate(network, [1,2,3,4])\n",
    "#backward_propagate_error(network, [0,1,2])\n",
    "#update_weights(network, [1,2,3,4],0.1)\n",
    "#for layer in network:\n",
    " #   print(layer)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GBH1C2i4UhP_"
   },
   "outputs": [],
   "source": [
    "# Train a network for a fixed number of epochs\n",
    "def train_network(network, X_train, l_rate, n_epoch, y_train):\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0\n",
    "        for row in X_train:\n",
    "            outputs = forward_propagate(network, row)\n",
    "            expected = [0 for i in range(y_train)]\n",
    "            #expected[row[-1]] = 1\n",
    "            sum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
    "            backward_propagate_error(network, expected)\n",
    "            update_weights(network, row, l_rate)\n",
    "        print('>epoch=%d, lrate=%.1f, error=%.3f' % (epoch, l_rate, sum_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nBhYkSOiUhQB"
   },
   "outputs": [],
   "source": [
    "# Make a prediction with a network\n",
    "def predict(network, row):\n",
    "    outputs = forward_propagate(network, row)\n",
    "    return outputs.index(max(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8YGPphmLUhQF",
    "outputId": "66f2e038-7bf0-4efd-af5b-1fa2550f3591"
   },
   "outputs": [],
   "source": [
    "# gyy\n",
    "\n",
    "n_outputs = len(set([row[-1] for row in X_train]))\n",
    "n_inputs = len(X_train[0]) - 1\n",
    "network = initialize_network(n_inputs, 3, n_outputs)\n",
    "train_network(network, X_train, 0.1, 5, n_outputs)\n",
    "print(predict(network, X_valid[0]))\n",
    "\n",
    "result_arr=[]\n",
    "for row in X_valid:\n",
    "    result=predict(network,row)\n",
    "    result_arr.append(result)\n",
    "print(result_arr)\n",
    "print(len(result_arr))\n",
    "#accuracy = (result_arr == y_valid).all(axis=(0,2)).mean()\n",
    "print(accuracy_score(np.array(y_valid), np.array(result_arr)[:, 2, :]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5dSPfhv8UhQI"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "   p(-x))\n",
    "\n",
    "def sigmoid_der(x):\n",
    "    return sigmoid(x) *(1-sigmoid (x))\n",
    "\n",
    "def softmax(A):\n",
    "    expA = np.exp(A)\n",
    "    return expA / expA.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hSZCB0ujUhQK"
   },
   "outputs": [],
   "source": [
    "hidden_nodes= 50\n",
    "bh = np.random.randn(1)\n",
    "wh = np.random.rand(784,hidden_nodes)\n",
    "wo = np.random.rand(hidden_nodes,4)\n",
    "bo = np.random.randn(4)\n",
    "for epoch in range(50000):\n",
    "## feedforward\n",
    "\n",
    "    # Phase 1\n",
    "    zh = np.dot(train_data, wh) + bh\n",
    "    ah = sigmoid(zh)\n",
    "\n",
    "    # Phase 2\n",
    "    zo = np.dot(ah, wo) + bo\n",
    "    ao = softmax(zo)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Question 4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
